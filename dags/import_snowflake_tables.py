# -*- coding: utf-8 -*-
"""import_snowflake_tables

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YijFEZL1JtfwbhqfsKlGaYEmel1MPFlw
"""

from airflow import DAG
from airflow.decorators import task
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from datetime import datetime, timedelta
import logging

def get_snowflake_conn():
    snowflake_hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')  # Your Snowflake connection ID
    return snowflake_hook.get_conn()

# Default DAG arguments
default_args = {
    'owner': 'Sreenidhi Hayagreevan',  # Your Name
    'start_date': datetime(2024, 10, 20),  # Updated start date
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# Define the DAG
with DAG(
    dag_id='import_snowflake_tables',
    default_args=default_args,
    schedule_interval=None,  # Run on-demand or adjust as needed
    catchup=False
) as dag:

    @task
    def create_tables():
        conn = get_snowflake_conn()
        cur = conn.cursor()
        try:
            cur.execute("USE DATABASE dev")
            cur.execute("USE SCHEMA raw_data")

            create_user_session_table = """
            CREATE TABLE IF NOT EXISTS raw_data.user_session_channel (
                userId int NOT NULL,
                sessionId varchar(32) PRIMARY KEY,
                channel varchar(32) DEFAULT 'direct'
            );
            """
            cur.execute(create_user_session_table)
            logging.info("Table raw_data.user_session_channel created successfully.")

            create_session_timestamp_table = """
            CREATE TABLE IF NOT EXISTS raw_data.session_timestamp (
                sessionId varchar(32) PRIMARY KEY,
                ts timestamp
            );
            """
            cur.execute(create_session_timestamp_table)
            logging.info("Table raw_data.session_timestamp created successfully.")
        except Exception as e:
            logging.error(f"Error creating tables: {e}")
            raise e
        finally:
            cur.close()
            conn.close()

    @task
    def set_stage():
        conn = get_snowflake_conn()
        cur = conn.cursor()
        try:
            cur.execute("USE DATABASE dev")
            cur.execute("USE SCHEMA raw_data")

            create_stage = """
            CREATE OR REPLACE STAGE raw_data.blob_stage
            url = 's3://s3-geospatial/readonly/'
            file_format = (type = csv, skip_header = 1, field_optionally_enclosed_by = '"');
            """
            cur.execute(create_stage)
            logging.info("Stage raw_data.blob_stage created successfully.")
        except Exception as e:
            logging.error(f"Error creating stage: {e}")
            raise e
        finally:
            cur.close()
            conn.close()

    @task
    def load_data():
        conn = get_snowflake_conn()
        cur = conn.cursor()
        try:
            cur.execute("USE DATABASE dev")
            cur.execute("USE SCHEMA raw_data")

            copy_user_session_channel = """
            COPY INTO raw_data.user_session_channel
            FROM @raw_data.blob_stage/user_session_channel.csv;
            """
            cur.execute(copy_user_session_channel)
            logging.info("Data copied into raw_data.user_session_channel successfully.")

            copy_session_timestamp = """
            COPY INTO raw_data.session_timestamp
            FROM @raw_data.blob_stage/session_timestamp.csv;
            """
            cur.execute(copy_session_timestamp)
            logging.info("Data copied into raw_data.session_timestamp successfully.")
        except Exception as e:
            logging.error(f"Error loading data: {e}")
            raise e
        finally:
            cur.close()
            conn.close()

    # Task dependencies
    create_tables_task = create_tables()
    set_stage_task = set_stage()
    load_data_task = load_data()

    create_tables_task >> set_stage_task >> load_data_task